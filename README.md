# ğŸ¤– AI Code Review Agent

A smart, pluggable, and local-friendly code review tool powered by LLMs (OpenAI, Anthropic, or Ollama). It analyzes Python scripts, detects bugs, reviews style, suggests improvements, and summarizes feedback in Markdown.

---

## ğŸš€ Features

- Accepts Python files or code snippets
- Reviews for:
  - âŒ Bugs
  - âœ¨ Style issues
  - ğŸ§ª Missing or weak tests
  - ğŸ§  Code clarity & suggestions
- Dual mode: Use OpenAI, Anthropic, or local Ollama models
- Prompt profiles (strict, mentor, test-focus)
- Output as clean Markdown in `reviews/review_output.md`

---

## ğŸ§± Project Structure

```
ai-project/
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ analyzer.py          # Prompt builder + code analysis
â”‚   â””â”€â”€ llm_interface.py     # Provider logic (OpenAI, Ollama, Anthropic)
â”œâ”€â”€ examples/                # Sample scripts to test
â”œâ”€â”€ prompts/templates.yaml   # Prompt profiles
â”œâ”€â”€ reviews/review_output.md# Review output
â”œâ”€â”€ cli.py                   # Command-line runner
â”œâ”€â”€ config.yaml              # API keys + model configs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Setup Instructions

### 1. ğŸ“¦ Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. ğŸ”‘ Add API Keys and Models

Edit `config.yaml`:

```yaml
openai:
  key: "YOUR_OPENAI_API_KEY"
  model: "gpt-4"

ollama:
  key: "YOUR_OLLAMA_API_KEY"
  model: "mistral"

anthropic:
  key: "YOUR_ANTHROPIC_API_KEY"
  model: "claude-3-opus-20240229"
```

> âœ… **Note**: Ollama requires you to have the model running locally. Start it with `ollama run mistral` before using.

---

## âš™ï¸ How to Run

### Basic Command

```bash
python cli.py --file examples/buggy_script.py --mode strict --provider openai
```

### Options

| Flag         | Description                                      |
| ------------ | ------------------------------------------------ |
| `--file`     | Path to the Python file to analyze               |
| `--mode`     | Prompt style: `strict`, `mentor` or `test_focus` |
| `--provider` | LLM backend: `openai`, `anthropic` or `ollama`   |

---

## ğŸ§ª Example Review Output

```markdown
## ğŸš¨ Bugs

- Variable `x` is used before assignment

## ğŸ’¡ Suggestions

- Use `with open(...)` to handle files safely
- Add tests for edge cases in function `parse_input`

## âœï¸ Style

- Line 24 exceeds 79 characters
```
